dtm
m <- as.matrix(dtm)
rowSums(m)
tokens <- sum(rowSums(m))
dname <- file.path("Data/Corpus") # Tells R the path to the files
dir(dname) # Lists the files in the directory/folder
ja_me_ot <- dir(dname)
docs <- Corpus(DirSource(dname)) # Create V corpus
docs <- tm_map(docs, removePunctuation)   # Remove punctuation
docs <- tm_map(docs, removeNumbers)      # Remove numbers
docs <- tm_map(docs, tolower)   # Convert to lowercase
docs <- tm_map(docs, stripWhitespace)   # Strip whitespace
dtm <- DocumentTermMatrix(docs)
docs <- tm_map(docs, PlainTextDocument)
dtm <- DocumentTermMatrix(docs)
m <- as.matrix(dtm)
rowSums(m)
tokens <- sum(rowSums(m))
docs <- tm_map(docs, removeWords, stopwords("english")) # To remove stopwords
docs <- tm_map(docs, stripWhitespace)   # Strip whitespace
docs <- tm_map(docs, PlainTextDocument)
dtm <- DocumentTermMatrix(docs)
dtm
m <- as.matrix(dtm)
rowSums(m)
tokens <- sum(rowSums(m))
rownames(m) <- ja_me_ot
d <- dist(m)
freq <- colSums(as.matrix(dtm))
length(freq)
ord <- order(freq,decreasing=TRUE)
freq[ord]
write.csv(freq[ord], "Results/Word_freq_.csv")
plot(freq[ord])
max(freq)
freq[max(freq)]
freq[which(freq == 10612)]
head(freq[ord])
freq_ord <- freq[ord]
plot(freq_ord[1:10])
rel_freqs <- 100 * (freq_ord / sum(freq_ord))
plot(rel_freqs[1:10], type = "b", main= "Relative frequencies in Corpus",
xlab = "Top Ten Words", ylab = "Percentage of Corpus")
library(wordVectors)
library(tsne)
library(Rtsne)
library(ggplot2)
library(ggrepel)
library(stringi)
library(magrittr)
library(igraph)
library(RColorBrewer)
library(visNetwork)
setwd("~/PhD_Main/Pilot/Pilot_Study")
prep_word2vec("Data/Corpus/", "Results/corpus_30.txt", lowercase =  T)
corp <- train_word2vec("Results/corpus_30.txt", output = "Results/corp.bin",
threads = 3, vectors = 100, window = 10)
w2v_analysis <- function(vsm, words, seed, path, ref_name) {
# Set the seed
if (!missing(seed))
set.seed(seed)
# Identify the nearest 10 words to the average vector of search terms
ten <- nearest_to(vsm, vsm[[words]])
# Identify the nearest 500 words to the average vector of search terms and
# save as a .txt file
main <- nearest_to(vsm, vsm[[words]], 500)
wordlist <- names(main)
filepath <- paste0(path, ref_name)
write(wordlist, paste0(filepath, ".txt"))
# Create a subset vector space model
new_model <- vsm[[wordlist, average = F]]
# Run Rtsne to reduce new VSM to 2D (Barnes-Hut)
reduction <- Rtsne(as.matrix(new_model), dims = 2, initial_dims = 50,
perplexity = 30, theta = 0.5, check_duplicates = F,
pca = F, max_iter = 1000, verbose = F,
is_distance = F, Y_init = NULL)
# Extract Y (positions for plot) as a dataframe and add row names
df <- as.data.frame(reduction$Y)
rows <- rownames(new_model)
rownames(df) <- rows
# Save dataframe as .csv file
write.csv(df, paste0(filepath, ".csv"))
# Create t-SNE plot and save as jpeg
ggplot(df) +
geom_point(aes(x = V1, y = V2), color = "red") +
geom_text_repel(aes(x = V1, y = V2, label = rownames(df))) +
xlab("Dimension 1") +
ylab("Dimension 2 ") +
# geom_text(fontface = 2, alpha = .8) +
theme_bw(base_size = 12) +
theme(legend.position = "none") +
ggtitle(paste0("2D reduction of VSM ", ref_name, " using t_SNE"))
ggsave(paste0(ref_name, ".jpeg"), path = path, width = 24,
height = 18, dpi = 100)
new_list <- list("Ten nearest" = ten, "Status" = "Analysis Complete")
return(new_list)
}
ind <- c("independence", "independent")
finance <- c("wealth", "property", "inheritance", "fortune")
marriage <- c("marriage", "wedding")
personal <- c("thought", "moral", "reason", "opinion", "belief")
status <- c("status", "rank", "position", "superior", "aristocracy", "gentry")
dependent <- c("dependent", "dependence")
set.seed(42)
centers <- 150
clustering <- kmeans(corp, centers = centers, iter.max = 40)
sapply(sample(1:centers, 10), function(n){
names(clustering$cluster[clustering$cluster ==n][1:10])
})
sapply(sample(1:centers, 15), function(n){
names(clustering$cluster[clustering$cluster ==n][1:10])
})
sapply(sample(1:centers, 29), function(n){
names(clustering$cluster[clustering$cluster ==n][1:10])
})
sapply(sample(1:centers, 20), function(n){
names(clustering$cluster[clustering$cluster ==n][1:10])
})
sapply(sample(1:centers, 15), function(n){
names(clustering$cluster[clustering$cluster ==n][1:10])
})
sapply(sample(1:centers, 18), function(n){
names(clustering$cluster[clustering$cluster ==n][1:10])
})
sapply(sample(1:centers, 16), function(n){
names(clustering$cluster[clustering$cluster ==n][1:10])
})
sapply(sample(1:centers, 15), function(n){
names(clustering$cluster[clustering$cluster ==n][1:10])
})
clusters <- sapply(sample(1:centers, 15), function(n){
names(clustering$cluster[clustering$cluster ==n][1:10])
})
View(clusters)
clusters <- sapply(sample(1:centers, 15), function(n){
names(clustering$cluster[clustering$cluster ==n][1:10])
})
clusters <- sapply(sample(1:centers, 15), function(n){
names(clustering$cluster[clustering$cluster ==n][1:10])
})
View(clusters)
write.csv(clusters, "Results/clusters_corp_30")
ind <- c("independence", "independent")
finance <- c("wealth", "property", "inheritance", "fortune")
marriage <- c("marriage", "wedding")
personal <- c("thought", "moral", "reason", "opinion", "belief")
status <- c("status", "rank", "position", "superior", "aristocracy", "gentry")
dependent <- c("dependent", "dependence")
term_set = lapply(ind, function(ind){
nearest_words = corp %>% nearest_to(corp[[ind]], 20) %>%
names
}) %>% unlist
subset1 <- ind[[term_set, average = F]]
subset1 <- ind[[term_set, average = F]]
subset1 <- corp[[term_set, average = F]]
subset1 %>%
cosineDist(subset1) %>%
as.dist %>%
hclust %>%
plot
subset1 %>%
cosineDist(subset1) %>%
as.dist %>%
hclust %>%
plot(main = "Independence Corpus 30")
ja <- read.vectors("Data/ja.bin")
term_set = lapply(ind, function(ind){
nearest_words = ja %>% nearest_to(ja[[ind]], 20) %>%
names
}) %>% unlist
subset1 <- ja[[term_set, average = F]]
subset1 %>%
cosineDist(subset1) %>%
as.dist %>%
hclust %>%
plot(main = "Independence JA")
me <- read.vectors("Data/me.bin")
term_set = lapply(ind, function(ind){
nearest_words = me %>% nearest_to(me[[ind]], 20) %>%
names
}) %>% unlist
subset1 <- me[[term_set, average = F]]
subset1 %>%
cosineDist(subset1) %>%
as.dist %>%
hclust %>%
plot(main = "Independence ME")
x <- nearest_to(corp, corp[["independent"]], 100)
y <- corp[[names(x), average = F]] # creates a VSM of nearest 100 words
sim <- cosineSimilarity(y, y) %>% round(2)
weight <- as.vector(sim)
g <- graph_from_incidence_matrix(sim)
e <- get.edgelist(g)
colnames(e) <- c("from", "to")
edf <- as.data.frame(e)
edf$weight <- weight
edf$weight <- weight[which(weight != 0)]
edf2 <- subset(edf, weight > 0.5)
edges <- as.matrix(edf2[, -3])
g2 <- graph(edges = edges)
plot(g2)
E(g2)$weight <- edf2$weight
g2 <- simplify(g2)
V(g2)$color<-ifelse(V(g2)$name=='independent', 'red', 'lightskyblue')
E(g2)$arrow.size <- 0.05
plot(g2)
visIgraph(g2)
visIgraph(g2) %>% visSave("Independent_corp_30.html")
ceb <- cluster_edge_betweenness(g2)
dendPlot(ceb, mode="hclust")
plot(ceb, g2)
cfg <- cluster_fast_greedy(as.undirected(g2))
plot(cfg, as.undirected(g2))
V(g2)$community <- cfg$membership
pal2 <- rainbow(10, alpha = 0.5)
plot(g2, vertex.color=pal2[V(g2)$community])
l <- layout_with_fr(g2)
plot(g2, vertex.color=pal2[V(g2)$community], layout = l)
l <- layout_with_kk(g2)
plot(g2, vertex.color=pal2[V(g2)$community], layout = l)
layout.by.attr <- function(graph, wc, cluster.strength=1,layout=layout.auto) {
g <- graph.edgelist(get.edgelist(graph)) # create a lightweight copy of graph w/o the attributes.
E(g)$weight <- 1
attr <- cbind(id=1:vcount(g), val=wc)
g <- g + vertices(unique(attr[,2])) + igraph::edges(unlist(t(attr)), weight=cluster.strength)
l <- layout(g, weights=E(g)$weight)[1:vcount(graph),]
return(l)
}
plot(g2,vertex.shape="none", vertex.size=0.75, edge.color = "gray90",
vertex.label.color=pal2[V(g2)$community], layout=layout.by.attr(g2, wc=5))
pal3 <- brewer.pal(11, "Paired")
plot(g2,vertex.shape="none", vertex.size=0.75, edge.color = "gray90",
vertex.label.color=pal3[V(g2)$community], layout=layout.by.attr(g2, wc=5))
pal3 <- brewer.pal(7, "Dark2")
plot(g2,vertex.shape="none", vertex.size=0.75, edge.color = "gray90",
vertex.label.color=pal3[V(g2)$community], layout=layout.by.attr(g2, wc=5))
plot(g2,vertex.shape="none", vertex.size=0.75, edge.color = "gray90",
vertex.label.color=pal3[V(g2)$community], layout=layout.by.attr(g2, wc=10))
plot(g2,vertex.shape="none", vertex.size=0.75, edge.color = "gray90",
vertex.label.color=pal3[V(g2)$community], layout=layout.by.attr(g2, wc=10),
main = "Independence 100 in Corpus 30")
V(g2)$color <- pal2[V(g2)$community]
visIgraph(g2)
visIgraph(g2, main = "Independence 100 in Corpus 30")
gr <- visIgraph(g2)
visLegend(gr, main = "Independence 100 in Corpus 30") %>%
visSave("Independence_100_Corpus 30_community.html")
visLegend(gr, main = "Independence 100 in Corpus 30")
x <- nearest_to(ja, ja[["independent"]], 100) # 100 nearest words to rising
y <- ja[[names(x), average = F]] # creates a VSM of nearest 100 words
sim <- cosineSimilarity(y, y) %>% round(2)
weight <- as.vector(sim)
g <- graph_from_incidence_matrix(sim)
e <- get.edgelist(g)
colnames(e) <- c("from", "to")
edf <- as.data.frame(e)
edf$weight <- weight[which(weight != 0)]
edf2 <- subset(edf, weight > 0.5)
edges <- as.matrix(edf2[, -3])
g2 <- graph(edges = edges)
plot(g2)
E(g2)$weight <- edf2$weight
g2 <- simplify(g2)
V(g2)$color<-ifelse(V(g2)$name=='independent', 'red', 'lightskyblue')
E(g2)$arrow.size <- 0.05
plot(g2)
visIgraph(g2)
visIgraph(g2) %>% visSave("Independent_JA.html")
ceb <- cluster_edge_betweenness(g2)
plot(ceb, g2)
cfg <- cluster_fast_greedy(as.undirected(g2))
plot(cfg, as.undirected(g2))
V(g2)$community <- cfg$membership
pal2 <- rainbow(10, alpha = 0.5)
plot(g2, vertex.color=pal2[V(g2)$community])
l <- layout_with_kk(g2)
plot(g2, vertex.color=pal2[V(g2)$community], layout = l)
pal3 <- brewer.pal(8, "Dark2")
plot(g2,vertex.shape="none", vertex.size=0.75, edge.color = "gray90",
vertex.label.color=pal3[V(g2)$community], layout=layout.by.attr(g2, wc=10),
main = "Independence 100 in JA")
plot(g2,vertex.shape="none", vertex.size=0.75, edge.color = "gray90",
vertex.label.color=pal3[V(g2)$community], layout=layout.by.attr(g2, wc=20),
main = "Independence 100 in JA")
V(g2)$color <- pal2[V(g2)$community]
visIgraph(g2)
visIgraph(g2) %>%
visSave("Independence_100_JA_community.html")
x <- nearest_to(me, me[["independent"]], 100) # 100 nearest words to rising
y <- me[[names(x), average = F]] # creates a VSM of nearest 100 words
sim <- cosineSimilarity(y, y) %>% round(2)
weight <- as.vector(sim)
g <- graph_from_incidence_matrix(sim)
e <- get.edgelist(g)
colnames(e) <- c("from", "to")
edf <- as.data.frame(e)
edf$weight <- weight[which(weight != 0)]
edf2 <- subset(edf, weight > 0.5)
edges <- as.matrix(edf2[, -3])
g2 <- graph(edges = edges)
plot(g2)
E(g2)$weight <- edf2$weight
g2 <- simplify(g2)
V(g2)$color<-ifelse(V(g2)$name=='independent', 'red', 'lightskyblue')
E(g2)$arrow.size <- 0.05
plot(g2)
visIgraph(g2)
visIgraph(g2) %>% visSave("Independent_ME.html")
ceb <- cluster_edge_betweenness(g2)
plot(ceb, g2)
cfg <- cluster_fast_greedy(as.undirected(g2))
plot(cfg, as.undirected(g2))
V(g2)$community <- cfg$membership
pal2 <- rainbow(10, alpha = 0.5)
plot(g2, vertex.color=pal2[V(g2)$community])
l <- layout_with_kk(g2)
plot(g2, vertex.color=pal2[V(g2)$community], layout = l)
pal3 <- brewer.pal(8, "Dark2")
plot(g2,vertex.shape="none", vertex.size=0.75, edge.color = "gray90",
vertex.label.color=pal3[V(g2)$community], layout=layout.by.attr(g2, wc=20),
main = "Independence 100 in ME")
plot(g2,vertex.shape="none", vertex.size=0.75, edge.color = "gray90",
vertex.label.color=pal3[V(g2)$community], layout=layout.by.attr(g2, wc=25),
main = "Independence 100 in ME")
plot(g2,vertex.shape="none", vertex.size=0.75, edge.color = "gray90",
vertex.label.color=pal3[V(g2)$community], layout=layout.by.attr(g2, wc=30),
main = "Independence 100 in ME")
V(g2)$color <- pal2[V(g2)$community]
visIgraph(g2)
visIgraph(g2) %>%
visSave("Independence_100_ME_community.html")
require(shiny)
require(visNetwork)
server <- function(input, output) {
output$network <- renderVisNetwork({
visIgraph(g2)
})
}
ui <- fluidPage(
visNetworkOutput("ME independence 100 Network")
)
shinyApp(ui = ui, server = server)
visIgraph(g2) %>% visSave("Independent_ME.html", selfcontained = T)
ui <- fluidPage(
visNetworkOutput("ME independence 100 Network")
)
server <- function(input, output) {
output$network <- renderVisNetwork({
visIgraph(g2)
})
}
shinyApp(ui = ui, server = server)
install.packages("rsconnect")
rsconnect::setAccountInfo(name='sarajkerr', token='31505A545C1D9D27BAC32D0DD1891B16', secret='Daye5NWd6opjq5DHGZeKlNLzTv93Klur2pgaqqT1')
dname <- file.path("Data/Corpus") # Tells R the path to the files
dname
dir(dname)
ja_me_ot <- dir(dname)
docs <- Corpus(DirSource(dname)) # Create V corpus
docs <- tm_map(docs, removePunctuation)   # Remove punctuation
docs <- tm_map(docs, removeNumbers)      # Remove numbers
docs <- tm_map(docs, tolower)   # Convert to lowercase
docs <- tm_map(docs, removeWords, stopwords("english")) # To remove stopwords
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, PlainTextDocument)
dtm <- DocumentTermMatrix(docs)
rownames(dtm) <- ja_me_ot
burnin = 1000
iter = 1000
keep = 50
full_data  <- dtm
n <- nrow(full_data)
cluster <- makeCluster(detectCores(logical = TRUE) - 1) # leave one CPU spare...
registerDoParallel(cluster)
clusterEvalQ(cluster, {
library(topicmodels)
})
cluster <- makeCluster(detectCores(logical = TRUE) - 1) # leave one CPU spare...
registerDoParallel(cluster)
clusterEvalQ(cluster, {
library(topicmodels)
})
cluster <- makeCluster(detectCores(logical = TRUE) - 1) # leave one CPU spare...
library(topicmodels)
library(doParallel)
library(ggplot2)
library(scales)
cluster <- makeCluster(detectCores(logical = TRUE) - 1) # leave one CPU spare...
registerDoParallel(cluster)
clusterEvalQ(cluster, {
library(topicmodels)
})
folds <- 5
splitfolds <- sample(1:folds, n, replace = TRUE)
candidate_k <- c(2, 3, 4, 5, 10, 15, 20, 25, 30, 50, 100) # how many topics
clusterExport(cluster, c("full_data", "burnin", "iter", "keep",
"splitfolds", "folds", "candidate_k"))
system.time({
results <- foreach(j = 1:length(candidate_k), .combine = rbind) %dopar%{
k <- candidate_k[j]
results_1k <- matrix(0, nrow = folds, ncol = 2)
colnames(results_1k) <- c("k", "perplexity")
for(i in 1:folds){
train_set <- full_data[splitfolds != i , ]
valid_set <- full_data[splitfolds == i, ]
fitted <- LDA(train_set, k = k, method = "Gibbs",
control = list(burnin = burnin, iter = iter, keep = keep) )
results_1k[i,] <- c(k, perplexity(fitted, newdata = valid_set))
}
return(results_1k)
}
})
prep_word2vec("Data/corpus_18W/", "Results/corp18.txt", lowercase =  T)
corp <- train_word2vec("Results/corp18.txt", output = "Data/Models/corp18.bin",
threads = 3, vectors = 100, window = 10)
write(ja_me_ot, "files.txt")
files <- cbind(1:30, ja_me_ot)
View(files)
write(files, "corpus30_list.txt")
files <- rbind(1:30, ja_me_ot)
View(files)
files <- cbind(1:30, ja_me_ot, nrows = 30)
View(files)
files <- cbind(1:30, ja_me_ot)
View(files)
write(files, "corpus30_list.txt", ncolumns = 2)
write(t(files), "corpus30_list.txt", ncolumns = 2)
term_set = lapply(ind, function(ind){
nearest_words = corp %>% nearest_to(corp[[ind]], 20) %>%
names
}) %>% unlist
subset1 <- corp[[term_set, average = F]]
subset1 %>%
cosineDist(subset1) %>%
as.dist %>%
hclust %>%
plot(main = "Independence Corpus 18")
x <- nearest_to(corp, corp[["independent"]], 100) # 100 nearest words to rising
y <- corp[[names(x), average = F]] # creates a VSM of nearest 100 words
sim <- cosineSimilarity(y, y) %>% round(2)
weight <- as.vector(sim)
g <- graph_from_incidence_matrix(sim)
e <- get.edgelist(g)
colnames(e) <- c("from", "to")
edf <- as.data.frame(e)
edf$weight <- weight[which(weight != 0)]
edf2 <- subset(edf, weight > 0.5)
edges <- as.matrix(edf2[, -3])
g2 <- graph(edges = edges)
plot(g2)
E(g2)$weight <- edf2$weight
g2 <- simplify(g2)
V(g2)$color<-ifelse(V(g2)$name=='independent', 'red', 'lightskyblue')
E(g2)$arrow.size <- 0.05
plot(g2)
visIgraph(g2)
visIgraph(g2) %>% visSave("Independent_Corpus18.html", selfcontained = T)
ceb <- cluster_edge_betweenness(g2)
plot(ceb, g2)
cfg <- cluster_fast_greedy(as.undirected(g2))
plot(cfg, as.undirected(g2))
V(g2)$community <- cfg$membership
pal2 <- rainbow(10, alpha = 0.5)
plot(g2, vertex.color=pal2[V(g2)$community])
pal3 <- brewer.pal(8, "Dark2")
lot(g2,vertex.shape="none", vertex.size=0.75, edge.color = "gray90",
vertex.label.color=pal3[V(g2)$community], layout=layout.by.attr(g2, wc=30),
main = "Independence 100 in Corpus 18")
plot(g2,vertex.shape="none", vertex.size=0.75, edge.color = "gray90",
vertex.label.color=pal3[V(g2)$community], layout=layout.by.attr(g2, wc=30),
main = "Independence 100 in Corpus 18")
plot(g2,vertex.shape="none", vertex.size=0.75, edge.color = "gray90",
vertex.label.color=pal3[V(g2)$community], layout=layout.by.attr(g2, wc=35),
main = "Independence 100 in Corpus 18")
plot(g2,vertex.shape="none", vertex.size=0.75, edge.color = "gray90",
vertex.label.color=pal3[V(g2)$community], layout=layout.by.attr(g2, wc=20),
main = "Independence 100 in Corpus 18")
plot(g2,vertex.shape="none", vertex.size=0.75, edge.color = "gray90",
vertex.label.color=pal3[V(g2)$community], layout=layout.by.attr(g2, wc=22),
main = "Independence 100 in Corpus 18")
V(g2)$color <- pal2[V(g2)$community]
V(g2)$color <- pal2[V(g2)$community]
visIgraph(g2)
visIgraph(g2) %>%
visSave("Independence_100_Corpus_18_community.html")
library(shiny)
runExample("01_hello")
runApp('Shiny/Networks/Network_Visualisations')
runApp('Shiny/Networks/Network_Visualisations')
runApp('Shiny/Networks/Network_Visualisations')
runApp('Shiny/Networks/Network_Visualisations')
runApp('Shiny/Networks/Network_Visualisations')
runApp('Shiny/Networks/Network_Visualisations')
runApp('Shiny/Networks/Network_Visualisations')
shiny::runApp(system.file("shiny", package = "visNetwork"))
t1 <- get.edge.ids(g2)
t1 <- get.edgelist(g2)
View(t1)
t2 <- get.edge.attribute(g2)
t3 <- get.vertex.attribute(g2)
visNetwork(nodes = t3, edges = t1)
visNetwork(edges = t1)
View(sim)
write.csv(sim, "corpus18_sim.csv")
runApp('Shiny/Networks/Network_Visualisations')
View(sim)
runApp('Shiny/Networks/Network_Visualisations')
runApp('Shiny/Networks/Network_Visualisations')
setwd("~/PhD_Main/Pilot/Pilot_Study/Shiny/Networks/Network_Visualisations")
sim <- read.csv("corpus18_sim.csv")
View(sim)
runApp()
